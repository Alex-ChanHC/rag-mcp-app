# Configuration for the RAG MCP Application

# Client UI Configuration
# Orchestrator LLM model to use
ORCHESTRATOR_MODEL="qwen3:1.7b"
# LLM provider for the RAG server ('ollama' or 'gemini')
RAG_LLM_PROVIDER="ollama"
# Port for the Gradio UI
GRADIO_PORT=3000

# RAG Server Configuration
# Path to the data directory
DATA_PATH="data"
# Path to the ChromaDB directory
CHROMA_PATH="chroma_db"
# Embeddings model to use (e.g., for Google Generative AI)
EMBEDDINGS_MODEL="models/embedding-001"
# LLM model to use for RAG (e.g., for Ollama)
RAG_LLM_MODEL="qwen3:1.7b"
# Number of results to retrieve from the vector store
RETRIEVER_NUM_RESULTS=5

# API Keys (if applicable)
# GOOGLE_API_KEY=your_google_api_key_here
